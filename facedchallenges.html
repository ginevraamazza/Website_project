<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Project KE4H: Faced Challenges</title>
  <link rel="stylesheet" href="assets/style.css">
</head>
<body>
  
 <nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="methodology.html">Methodology</a></li>
      <li><a href="sparqlqueries.html">SPARQL Queries</a></li>
      <li>
        <a href="#">Monuments</a>
        <ul>
          <li><a href="arcodaugusto.html">Arco d'Augusto</a></li>
          <li><a href="tempiomalatestiano.html">Tempio Malatestiano</a></li>
          <li><a href="domusdelchirurgo.html">Domus del Chirurgo</a></li>
          <li><a href="ponteditiberio.html">Ponte di Tiberio</a></li>
          <li><a href="chiesadisantagostino.html">Chiesa di Sant'Agostino</a></li>
        </ul>
      </li>
      <li><a href="facedchallenges.html">Faced Challenges</a></li>
      <li><a href="conclusions.html">Conclusions</a></li>
    </ul>
 </nav>

  <main>
    <br>
    <br>
    <h1 id="arch-title" class="anchor-offset">Faced Challenges</h1>
    <br><br>
    <p>This KE4H project presented various challenges that sharpened both our technical abilities and our inventive problem-solving. 
	In this section we describe the primary difficulties we encountered and the successful approaches we took to resolve them. </p>
	<br>
	<h2>1. &#129300 SPARQL Queries Complexity</h2>
	<br><br>
    <p>Formulating SPARQL queries that return precise, meaningful data from <strong><a href="https://www.wikidata.org/wiki/Wikidata:Main_Page" class="no-underline-link"</a> Wikidata</a></strong> was not always easy, especially because SPARQL is very sensitive to syntax: 
	 missing semicolons, full stops, parenthesis or incorrect prefixes can lead to errors that are sometimes hard to debug, and a lot of time is required to correct them. </p>
	<br>
	<p>Therefore, we refined use of key constructs like <strong class="highlighted-strong">UNION</strong>, <strong class="highlighted-strong">OPTIONAL</strong>, 
	<strong class="highlighted-strong">FILTER</strong>, <strong class="highlighted-strong">REGEX</strong> and <strong class="highlighted-strong">CONSTRUCT</strong> to define our data retrieval and construction logic,
	and we used <strong><a href="https://en.wikipedia.org/wiki/Large_language_model" class="no-underline-link">LLMs</a></strong> to help us with the syntax of the queries (notably to find mistakes within the code).</p><br>
    <h2>2. &#10060 Mistakes in LLMs outputs</h2>
    <br><br>
    <p>When prompting <strong><a href="https://chatgpt.com/auth/login" class="no-underline-link"</a>Chat GPT</a></strong>, <strong><a href="https://www.deepseek.com/en" class="no-underline-link"</a>Deep Seek</a> </strong> and <strong><a href="https://gemini.google.com/app?hl=itGemini" class="no-underline-link"</a>Gemini</a></strong> to generate RDF triples using the Wikidata ontology, the models often returned incorrect or non-existent Q-IDs.
	This is part of <strong><a href="https://medium.com/@gcentulani/understanding-hallucination-in-llms-causes-consequences-and-mitigation-strategies-b5e1d0268069" class="no-underline-link"</a> hallucination</a></strong> that occurs within LLMs. 
	Here is an example of a query proposed by Chat GPT in one of its answers:</p>
    <pre class="code-frame" style="max-width: 1000 px;"><code>
	<strong>SELECT</strong> ?artwork ?artworkLabel WHERE {
		?artwork wdt:P31/wdt:P279* wd:Q838948 .
	<strong>VALUES</strong> ?location <s>{ wd:Q351395 }</s> <strong><span style="color:green;">{ wd:Q1268593 } </span></strong>
	{
		?artwork wdt:P276 ?location .
	}
	<strong>UNION</strong>
	{
		?artwork wdt:P131 ?location .
	}
	SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
	}
	 </p>
	 </code></pre>
	 <br>
	 <p> The Q-ID of the Malatestan Temple proposed (Q1268593) was clearly wrong and had to be manually corrected to receive relevant results.
	 Therefore, we had to manually rewrite almost each Q-ID and sometimes even properties by looking them up directly in Wikidata. 
	 This step clearly improved the relevance of our enrichment.</p>
	 <br>
    <h2>3. &#128187 Building and structuring the website</h2>
    <br>
    <br>
    <p>Before creating this project, none of us had any prior experience building a website. 
	<br><br>
	3.1 We started by using a <strong><a href="https://docs.github.com/en/repositories/creating-and-managing-repositories/creating-a-repository-from-a-template" class="no-underline-link"</a>Github template</a></strong>, as they were readily available, but we encountered many difficulties in modifying it to fit our needs (one of the difficulties for example was adding a fixed menu on top). 
	After several attempts, we decided to build it from scratch, getting help with the syntax we didn't know from chatbots. <br><br>
	3.2 Then to edit our website, some of us used an application called <strong><a href="https://en.wikipedia.org/wiki/Notepad%2B%2B" class="no-underline-link"</a>Notepad++</a></strong> (click <strong><a href="https://notepad-plus-plus.org/downloads/" class="no-underline-link"</a> here<a></strong> to download the most recent version 8.8.1), which was a real game-changer! 
	Unlike standard Notepad, Notepad++ highlights code with different colors, making it much easier to read, understand, and debug our work. This visual aid significantly streamlined our coding process. <br><br> Here is an example of some code from Notepad++: </p>
    <div style="text-align: center;">
  <img src="images/notepad.jpg" width="1000">
</div>
<p>
<br>
   Meanwhile, others among us utilized <strong><a href="https://www.w3schools.com/" class="no-underline-link"</a> W3Schools<a></strong> as another valuable resource for editing and learning. Here is the visual representation: </p>
<div style="text-align: center;">
  <img src="images/w3school.jpg" width="1000">
</div>
<br><br>	
	<p> 3.3 Another challenge was inserting links to the query results, as copying those provided by Wikidata's SPARQL into the HTML code didn't work. 
	When we asked the chatbots to provide them, we noticed the difference was in the following characters: <span class="query-keyword"> < </span>, <span class="query-keyword"> > </span>, <span class="query-keyword">(</span>, <span class="query-keyword">)</span> and <span class="query-keyword"> " </span>. 
	These were simply being replaced with their <strong><a href="https://en.wikipedia.org/wiki/ASCII" class="no-underline-link"</a> ASCII codes<a></strong>. By replacing these characters with their respective <strong><a href="https://www.ascii-code.com/it" class="no-underline-link"</a> ASCII equivalents</a></strong>, the results started working.
    The column we looked at in the link was the HEX column. Naturally, the value was preceded by the <span class="query-keyword"> % </span> prefix, which indicates that the following value is hexadecimal. <br><br>
    This way, we created the links much faster than asking ChatGPT every time, simply by finding the problematic characters and replacing them.
	</p>
  </main>
<div class="internal-nav-1">
  <p><a href="#arch-title" class="no-underline-link">Get back at the beginning of the page</a></p>
</div> 
<div id="footer_wrap">
 <footer class="inner">
        <p style="color: white; font-size: 1.1em;">Website published with <a href="https://pages.github.com" class="no-underline-link github-pages-link-hover" style="color: white;"> GitHub Pages</a></p>
      </footer>
    </div>
</body>
</html>

</body>
</html>
